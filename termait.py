import os
import sys
import argparse
import subprocess
import json
from abc import ABC, abstractmethod
from typing import Optional, Dict, Any, List

from anthropic import Anthropic
from openai import OpenAI
from rich.console import Console
from rich.panel import Panel
from rich.prompt import Confirm
import re

# Initialize Rich console
console = Console()

def get_system_prompt() -> str:
    shell = os.environ.get("SHELL", "unknown")
    os_name = sys.platform
    return f"""You are an expert terminal command generator. 
    The user's OS is: {os_name}.
    The user's Shell is: {shell}.
    
    Your task is to translate natural language requests into the most appropriate terminal command.
    
    CRITICAL OUTPUT INSTRUCTIONS:
    1. You MUST output a valid JSON object.
    2. The JSON must have exactly two keys: "command" and "explanation".
    3. Do NOT wrap the JSON in markdown code blocks.
    4. Do NOT include any other text before or after the JSON.
    
    Example:
    {{
        "command": "ls -la",
        "explanation": "List all files including hidden ones."
    }}
    """

class LLMProvider(ABC):
    @abstractmethod
    def generate_command(self, prompt: str) -> str:
        pass
    
    @property
    @abstractmethod
    def name(self) -> str:
        pass

class AnthropicProvider(LLMProvider):
    def __init__(self, api_key: str, model: str = "claude-3-5-sonnet-20241022", base_url: Optional[str] = None):
        self.model = model
        kwargs = {"api_key": api_key}
        if base_url:
            kwargs["base_url"] = base_url
        self.client = Anthropic(**kwargs)

    @property
    def name(self) -> str:
        return f"Anthropic ({self.model})"

    def generate_command(self, prompt: str) -> str:
        messages = [
            {"role": "user", "content": f"Generate a terminal command for: {prompt}. \n\nIMPORTANT: Return a JSON object with 'command' and 'explanation' keys. JSON ONLY."}
        ]
        response = self.client.messages.create(
            model=self.model,
            max_tokens=1024,
            system=get_system_prompt(),
            messages=messages
        )
        return response.content[0].text

class OpenAIProvider(LLMProvider):
    def __init__(self, api_key: str, base_url: Optional[str] = None, model: str = "gpt-4o"):
        self.model = model
        # Default to a dummy key if using a local provider that doesn't need one, 
        # but OpenAI client requires something.
        if not api_key and base_url:
            api_key = "dummy-key"
        
        self.client = OpenAI(api_key=api_key, base_url=base_url)

    @property
    def name(self) -> str:
        return f"OpenAI/Local ({self.model})"

    def generate_command(self, prompt: str) -> str:
        messages = [
            {"role": "system", "content": get_system_prompt()},
            {"role": "user", "content": f"Generate a terminal command for: {prompt}. \n\nIMPORTANT: Return a JSON object with 'command' and 'explanation' keys. JSON ONLY."}
        ]
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            max_tokens=1024
        )
        return response.choices[0].message.content

def process_request(prompt: str, provider: LLMProvider):
    try:
        with console.status(f"[bold green]Generating command using {provider.name}...", spinner="dots"):
            content = provider.generate_command(prompt)
            
        try:
            # Strategy 1: Regex for JSON
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
                data = json.loads(json_str)
                command = data["command"]
                explanation = data["explanation"]
            else:
                raise ValueError("No JSON found")
        except (json.JSONDecodeError, AttributeError, KeyError, ValueError):
            # Strategy 2: Fallback to Code Block
            code_block_match = re.search(r'```(?:bash|sh|zsh)?\s*(.*?)\s*```', content, re.DOTALL)
            if code_block_match:
                command = code_block_match.group(1).strip()
                explanation = re.sub(r'```.*?```', '', content, flags=re.DOTALL).strip()
                lines = [l.strip() for l in explanation.split('\n') if l.strip()]
                explanation = lines[0] if lines else "Command generated by AI."
            else:
                console.print("[red]Error: Failed to parse AI response. Raw output:[/red]")
                console.print(content)
                return

        console.print(Panel(f"[bold white]{command}[/bold white]", title="Proposed Command", border_style="green"))
        console.print(f"[italic]{explanation}[/italic]")
        
        if Confirm.ask("Do you want to execute this command?"):
            console.print(f"[bold]Running:[/bold] {command}")
            subprocess.run(command, shell=True)
            console.print("[green]Done![/green]")
        else:
            console.print("[yellow]Cancelled.[/yellow]")

    except Exception as e:
        console.print(f"[red]Error:[/red] {e}")

def load_config() -> Dict[str, Any]:
    """Load configuration from ~/.termait or ~/.config/termait/config.json"""
    home = os.path.expanduser("~")
    config_paths = [
        os.path.join(home, ".termait"),
        os.path.join(home, ".config", "termait", "config.json"),
    ]
    
    for path in config_paths:
        if os.path.exists(path):
            try:
                with open(path, "r") as f:
                    return json.load(f)
            except json.JSONDecodeError:
                console.print(f"[yellow]Warning: Failed to parse config file at {path}[/yellow]")
    
    return {}

def main():
    parser = argparse.ArgumentParser(description="TermAIt: AI-powered terminal command generator")
    parser.add_argument("prompt", nargs="*", help="Natural language description of the command")
    parser.add_argument("--provider", choices=["anthropic", "openai"], help="LLM provider to use")
    parser.add_argument("--model", help="Model to use (overrides default)")
    parser.add_argument("--api-base", help="Base URL for the API (useful for local models)")
    args = parser.parse_args()

    initial_prompt = " ".join(args.prompt) if args.prompt else None
    
    if not initial_prompt:
        parser.print_help()
        return

    # Load config file
    config = load_config()

    # Determine settings with precedence: CLI > Env > Provider Config > Global Config > Default
    
    # Provider is always top-level or derived
    provider_name = (
        args.provider 
        or os.environ.get("TERMAIT_PROVIDER") 
        or config.get("provider") 
        or "anthropic"
    )
    
    # Get provider-specific config section
    provider_config = config.get(provider_name, {})
    if not isinstance(provider_config, dict):
        provider_config = {}

    # Helper to get config value
    def get_val(key: str, default: Any = None) -> Any:
        return (
            provider_config.get(key) 
            or config.get(key) 
            or default
        )

    # Provider setup
    provider: LLMProvider
    
    if provider_name == "anthropic":
        api_key = (
            os.environ.get("ANTHROPIC_API_KEY") 
            or os.environ.get("ANTHROPIC_AUTH_TOKEN")
            or get_val("api_key")
        )
        if not api_key:
            console.print("[red]Error: ANTHROPIC_API_KEY or ANTHROPIC_AUTH_TOKEN not set.[/red]")
            sys.exit(1)
        
        model = (
            args.model 
            or os.environ.get("ANTHROPIC_MODEL") 
            or get_val("model")
            or "claude-3-5-sonnet-20241022"
        )
        
        base_url = (
            args.api_base 
            or os.environ.get("ANTHROPIC_BASE_URL")
            or get_val("api_base")
        )
        
        provider = AnthropicProvider(api_key=api_key, model=model, base_url=base_url)
        
    elif provider_name == "openai":
        api_key = (
            os.environ.get("OPENAI_API_KEY")
            or get_val("api_key")
        )
        
        model = (
            args.model 
            or os.environ.get("OPENAI_MODEL") 
            or get_val("model")
            or "gpt-4o"
        )
        
        base_url = (
            args.api_base 
            or os.environ.get("OPENAI_API_BASE")
            or get_val("api_base")
            or get_val("base_url") # Common alias
        )
        
        if not api_key and not base_url:
             console.print("[red]Error: OPENAI_API_KEY not set (or create local endpoint with --api-base).[/red]")
             sys.exit(1)
             
        provider = OpenAIProvider(api_key=api_key, model=model, base_url=base_url)
        
    else:
        console.print(f"[red]Unknown provider: {provider_name}[/red]")
        sys.exit(1)

    process_request(initial_prompt, provider)

if __name__ == "__main__":
    main()
